{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d42670f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librer√≠as importadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import spacy\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils import resample\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Dropout, Conv1D, MaxPooling1D, Flatten, Input\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, SpatialDropout1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "print(\"Librer√≠as importadas correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4778524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos listos. Entrenamiento: 5537 filas. Prueba: 1385 filas.\n",
      "Clases detectadas: 12\n",
      "0: CARDIOLOG√çA/CIRCULATORIO\n",
      "1: DERMATOLOG√çA\n",
      "2: ENDOCRINOLOG√çA/NUTRICI√ìN\n",
      "3: GASTROENTEROLOG√çA/DIGESTIVO\n",
      "4: GINECOLOG√çA/OBSTETRICIA\n",
      "5: NEUROLOG√çA\n",
      "6: OFTALMOLOG√çA/ORL\n",
      "7: ONCOLOG√çA (TUMORES)\n",
      "8: PSIQUIATR√çA/MENTAL\n",
      "9: S√çNTOMAS GENERALES/NO CLASIFICADOS\n",
      "10: TRAUMATOLOG√çA/MUSCULAR\n",
      "11: UROLOG√çA/RENAL\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos\n",
    "df_procesados = pd.read_csv('../data/datos_nlp_procesados_2.csv')\n",
    "\n",
    "# Filtrar clases muy peque√±as (opcional, para evitar errores si hay solo 1 ejemplo)\n",
    "conteo = df_procesados['especialidad_corr'].value_counts()\n",
    "clases_validas = conteo[conteo > 5].index\n",
    "df_procesados = df_procesados[df_procesados['especialidad_corr'].isin(clases_validas)]\n",
    "\n",
    "# Convertir etiquetas de texto a n√∫meros (Cardiolog√≠a -> 0, Respiratorio -> 1...)\n",
    "label_encoder = LabelEncoder()\n",
    "df_procesados['label_num'] = label_encoder.fit_transform(df_procesados['especialidad_corr'])\n",
    "# Separar datos de entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_procesados['sintomas_procesados'], \n",
    "    df_procesados['label_num'], \n",
    "    test_size=0.20, \n",
    "    random_state=42,\n",
    "    stratify=df_procesados['label_num'] # Mantiene la proporci√≥n de clases\n",
    ")\n",
    "\n",
    "print(f\"Datos listos. Entrenamiento: {len(X_train)} filas. Prueba: {len(X_test)} filas.\")\n",
    "print(\"Clases detectadas:\", len(label_encoder.classes_))\n",
    "\n",
    "# Mostrar las clases\n",
    "for i, clase in enumerate(label_encoder.classes_):\n",
    "    print(f\"{i}: {clase}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a9662b",
   "metadata": {},
   "source": [
    "## Modelo SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e584a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Vectorizaci√≥n (Convertir texto a matriz de n√∫meros con TF-IDF)\n",
    "tfidf = TfidfVectorizer(max_features=5000) # Usaremos las 5000 palabras m√°s importantes\n",
    "X_train_tfidf = tfidf.fit_transform(X_train).toarray()\n",
    "X_test_tfidf = tfidf.transform(X_test).toarray()\n",
    "\n",
    "# 2. Entrenar Modelo SVM (Support Vector Machine)\n",
    "print(\"ü§ñ Entrenando modelo cl√°sico (SVM)...\")\n",
    "svm_model = SVC(kernel='linear', random_state=42, class_weight='balanced')\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# 3. Evaluar\n",
    "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
    "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"‚úÖ Precisi√≥n del Modelo Cl√°sico (SVM): {acc_svm*100:.2f}%\")\n",
    "print(\"\\nReporte de Clasificaci√≥n:\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=label_encoder.classes_, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44358757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# üöÄ ESTRATEGIA AVANZADA PARA SVM (>80%)\n",
    "# ==========================================\n",
    "\n",
    "print(\"ü§ñ Iniciando optimizaci√≥n avanzada del SVM (Esto puede tardar unos minutos)...\")\n",
    "\n",
    "# 1. Definimos un 'Pipeline' (Tuber√≠a de procesos)\n",
    "# Esto asegura que el preprocesamiento y el modelo viajen juntos\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        strip_accents='unicode',\n",
    "        lowercase=True\n",
    "    )),\n",
    "    ('svm', SVC(class_weight='balanced', probability=True))\n",
    "])\n",
    "\n",
    "# 2. Definimos la 'Rejilla de Hiperpar√°metros' (El men√∫ de opciones a probar)\n",
    "# La IA probar√° todas estas combinaciones para encontrar la ganadora\n",
    "param_grid = {\n",
    "    # B√∫squeda de N-Grams:\n",
    "    # (1,1) = Solo palabras sueltas\n",
    "    # (1,2) = Palabras sueltas Y parejas (\"dolor de\", \"de pecho\") -> CR√çTICO EN MEDICINA\n",
    "    'tfidf__ngram_range': [(1, 2)], \n",
    "    \n",
    "    # Limpieza de vocabulario:\n",
    "    # min_df=2: Ignora palabras que aparecen en menos de 2 documentos (errores tipogr√°ficos)\n",
    "    'tfidf__min_df': [2, 3],\n",
    "    \n",
    "    # max_features: Probamos con m√°s palabras o sin l√≠mite\n",
    "    'tfidf__max_features': [5000, 7000, None],\n",
    "    \n",
    "    # Par√°metros del SVM:\n",
    "    # C: Qu√© tan estricto es el modelo (Valores altos = menos errores en train, riesgo de overfitting)\n",
    "    # kernel: La forma matem√°tica de separar los datos\n",
    "    'svm__C': [1, 10, 100],\n",
    "    'svm__kernel': ['linear', 'rbf'] \n",
    "}\n",
    "\n",
    "# 3. Ejecutar GridSearch (Fuerza Bruta Inteligente)\n",
    "# cv=5 significa Validaci√≥n Cruzada de 5 pliegues (entrena 5 veces con distintos trozos de datos)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "\n",
    "# Entrenar\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# ==========================================\n",
    "# üèÜ RESULTADOS\n",
    "# ==========================================\n",
    "print(f\"\\n‚úÖ ¬°Optimizaci√≥n completada!\")\n",
    "print(f\"Mejores par√°metros encontrados: {grid_search.best_params_}\")\n",
    "print(f\"Mejor precisi√≥n en validaci√≥n cruzada: {grid_search.best_score_*100:.2f}%\")\n",
    "\n",
    "# Guardamos el mejor modelo\n",
    "best_svm = grid_search.best_estimator_\n",
    "\n",
    "# 4. Evaluaci√≥n Final en el set de Prueba (Test)\n",
    "y_pred_svm = best_svm.predict(X_test)\n",
    "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"\\nüèÜ PRECISI√ìN FINAL EN TEST: {acc_svm*100:.2f}%\")\n",
    "print(\"\\nReporte de Clasificaci√≥n Detallado:\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=label_encoder.classes_, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be429b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo mejorado\n",
    "with open('../models/modelo_svm_optimizado.pkl', 'wb') as f:\n",
    "    pickle.dump(best_svm, f)\n",
    "print(\"üíæ Modelo optimizado guardado en '../models/modelo_svm_optimizado.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b567a0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Entrenando Modelo Final con clases corregidas...\n",
      "\n",
      "üåü PRECISI√ìN FINAL: 82.45%\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "          CARDIOLOG√çA/CIRCULATORIO       0.94      0.91      0.92       229\n",
      "                      DERMATOLOG√çA       0.91      0.67      0.77        15\n",
      "          ENDOCRINOLOG√çA/NUTRICI√ìN       0.74      0.77      0.76        22\n",
      "       GASTROENTEROLOG√çA/DIGESTIVO       0.90      0.89      0.89       142\n",
      "           GINECOLOG√çA/OBSTETRICIA       0.90      0.89      0.89        62\n",
      "                        NEUROLOG√çA       0.71      0.76      0.73       185\n",
      "                  OFTALMOLOG√çA/ORL       0.89      0.95      0.92        96\n",
      "               ONCOLOG√çA (TUMORES)       0.53      0.64      0.58        42\n",
      "                PSIQUIATR√çA/MENTAL       0.84      0.84      0.84        25\n",
      "S√çNTOMAS GENERALES/NO CLASIFICADOS       0.68      0.75      0.71       154\n",
      "            TRAUMATOLOG√çA/MUSCULAR       0.84      0.79      0.82       281\n",
      "                    UROLOG√çA/RENAL       0.92      0.82      0.86       132\n",
      "\n",
      "                          accuracy                           0.82      1385\n",
      "                         macro avg       0.82      0.81      0.81      1385\n",
      "                      weighted avg       0.83      0.82      0.83      1385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# üèÜ ENTRENAMIENTO FINAL (MEJOR MODELO)\n",
    "# ==========================================\n",
    "\n",
    "# Usamos los par√°metros ganadores del GridSearch anterior\n",
    "pipeline_final = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        ngram_range=(1, 2),    # Bigramas (Clave)\n",
    "        min_df=2,              # Ignorar errores √∫nicos\n",
    "        max_features=None,     # Usar todo el vocabulario\n",
    "        strip_accents='unicode',\n",
    "        lowercase=True\n",
    "    )),\n",
    "    ('svm', SVC(\n",
    "        C=100,                 # Margen estricto\n",
    "        kernel='linear',       # Separaci√≥n lineal\n",
    "        class_weight='balanced', \n",
    "        probability=True       # Para ver % de confianza en la demo\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"üöÄ Entrenando Modelo Final con clases corregidas...\")\n",
    "pipeline_final.fit(X_train, y_train)\n",
    "\n",
    "# Evaluaci√≥n\n",
    "y_pred = pipeline_final.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nüåü PRECISI√ìN FINAL: {acc*100:.2f}%\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09f3e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar\n",
    "with open('../models/modelo_svm_final_80.pkl', 'wb') as f:\n",
    "    pickle.dump(pipeline_final, f)\n",
    "    \n",
    "# Guardar tambi√©n el nuevo encoder (¬°Muy importante porque cambiamos las clases!)\n",
    "with open('../models/label_encoder_final_80.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f7835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# üèÜ DEMO FINAL: USANDO EL MODELO (SVM)\n",
    "# ==========================================\n",
    "\n",
    "# Cargar el modelo guardado\n",
    "with open('../models/modelo_svm_final_80.pkl', 'rb') as f:\n",
    "    modelo_cargado = pickle.load(f)\n",
    "# Cargar el label encoder guardado\n",
    "with open('../models/label_encoder_final_80.pkl', 'rb') as f:\n",
    "    label_encoder_cargado = pickle.load(f)\n",
    "\n",
    "# Ejemplo de uso\n",
    "def predecir_especialidad(sintomas):\n",
    "    prediccion_num = modelo_cargado.predict([sintomas])[0]\n",
    "    prediccion_texto = label_encoder_cargado.inverse_transform([prediccion_num])[0]\n",
    "    return prediccion_texto\n",
    "ejemplo_sintomas = [\"Paciente con dolor tor√°cico intenso, dificultad para respirar y sudoraci√≥n profusa.\",\n",
    "                    \"Fiebre alta, tos persistente y dolor de garganta desde hace tres d√≠as.\",\n",
    "                    \"Dolor abdominal severo, n√°useas y v√≥mitos despu√©s de comer.\",\n",
    "                    \"Mareos, visi√≥n borrosa y debilidad en las extremidades.\",\n",
    "                    \"Erupci√≥n cut√°nea con picaz√≥n intensa y ampollas en varias partes del cuerpo.\",\n",
    "                    \"Dolor de cabeza intenso, rigidez en el cuello y sensibilidad a la luz.\",\n",
    "                    \"Dolor en las articulaciones, hinchaz√≥n y dificultad para moverse.\",\n",
    "                    \"Dificultad para respirar, sibilancias y opresi√≥n en el pecho.\",\n",
    "                    \"Dolor lumbar severo, entumecimiento en las piernas y p√©rdida de control de la vejiga.\",\n",
    "                    \"Fatiga extrema, p√©rdida de peso inexplicada y sudores nocturnos.\",\n",
    "                    ]\n",
    "for sintomas in ejemplo_sintomas:\n",
    "    especialidad_predicha = predecir_especialidad(sintomas)\n",
    "    print(f\"Sintomas: {sintomas}\\n‚û°Ô∏è Especialidad Predicha: {especialidad_predicha}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d229e97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Iniciando Triaje con Modelo SVM (Campe√≥n)...\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# --- PRUEBA FINAL ---\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müöÄ Iniciando Triaje con Modelo SVM (Campe√≥n)...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[43mpredecir_con_svm\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEl paciente presenta dolor fuerte en el pecho y dificultad para respirar\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m predecir_con_svm(\u001b[33m\"\u001b[39m\u001b[33mMancha roja en la piel que pica y arde\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     49\u001b[39m predecir_con_svm(\u001b[33m\"\u001b[39m\u001b[33mP√©rdida de visi√≥n en el ojo derecho borroso\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mpredecir_con_svm\u001b[39m\u001b[34m(texto_usuario)\u001b[39m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# 2. Vectorizaci√≥n (Usamos TF-IDF en lugar del Tokenizer)\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Importante: Usamos .transform(), NO .fit_transform()\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m vector_numerico = \u001b[43mtfidf\u001b[49m.transform([texto_limpio]).toarray()\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# 3. Predicci√≥n con SVM\u001b[39;00m\n\u001b[32m     33\u001b[39m prediccion_index = svm_model.predict(vector_numerico)[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# üèÜ DEMO FINAL: USANDO EL MODELO (SVM)\n",
    "# ==========================================\n",
    "# Nota: Usamos el SVM porque demostr√≥ ser m√°s robusto con la cantidad actual de datos.\n",
    "try:\n",
    "    nlp = spacy.load(\"es_core_news_sm\")\n",
    "except:\n",
    "    import os\n",
    "    os.system(\"python -m spacy download es_core_news_sm\")\n",
    "    nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "def procesar_texto_para_demo(texto):\n",
    "    doc = nlp(texto)\n",
    "    tokens_limpios = []\n",
    "    for token in doc:\n",
    "        if not token.is_punct and not token.is_stop and token.is_alpha:\n",
    "            tokens_limpios.append(token.lemma_.lower())\n",
    "    return \" \".join(tokens_limpios)\n",
    "\n",
    "def predecir_con_svm(texto_usuario):\n",
    "    # 1. Limpieza (Igual que siempre)\n",
    "    texto_limpio = procesar_texto_para_demo(texto_usuario)\n",
    "    \n",
    "    if not texto_limpio:\n",
    "        print(\"‚ö†Ô∏è Escribe algo con sentido m√©dico.\")\n",
    "        return\n",
    "\n",
    "    # 2. Vectorizaci√≥n (Usamos TF-IDF en lugar del Tokenizer)\n",
    "    # Importante: Usamos .transform(), NO .fit_transform()\n",
    "    vector_numerico = tfidf.transform([texto_limpio]).toarray()\n",
    "    \n",
    "    # 3. Predicci√≥n con SVM\n",
    "    prediccion_index = svm_model.predict(vector_numerico)[0]\n",
    "    \n",
    "    # El SVM a veces no da probabilidades directas, pero su predicci√≥n es s√≥lida\n",
    "    etiqueta = label_encoder.inverse_transform([prediccion_index])[0]\n",
    "    \n",
    "    # 4. Mostrar resultado\n",
    "    print(f\"üë§ Usuario: '{texto_usuario}'\")\n",
    "    print(f\"‚öôÔ∏è Procesado: '{texto_limpio}'\")\n",
    "    print(f\"üè• Especialidad: {etiqueta.upper()}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# --- PRUEBA FINAL ---\n",
    "print(\"üöÄ Iniciando Triaje con Modelo SVM (Campe√≥n)...\\n\")\n",
    "\n",
    "predecir_con_svm(\"El paciente presenta dolor fuerte en el pecho y dificultad para respirar\")\n",
    "predecir_con_svm(\"Mancha roja en la piel que pica y arde\")\n",
    "predecir_con_svm(\"P√©rdida de visi√≥n en el ojo derecho borroso\")\n",
    "predecir_con_svm(\"Fractura de hueso por ca√≠da fuerte\")\n",
    "predecir_con_svm(\"Ardor al orinar y dolor en los ri√±ones\")\n",
    "predecir_con_svm(\"El paciente presenta dolor fuerte en el pecho y dificultad para respirar\")\n",
    "predecir_con_svm(\"Tengo una mancha roja en la piel que me pica mucho\")\n",
    "predecir_con_svm(\"Dolor intenso en el ojo derecho y visi√≥n borrosa\")\n",
    "predecir_con_svm(\"Fractura en la pierna tras ca√≠da\")\n",
    "predecir_con_svm(\"Ardor al orinar y dolor en los ri√±ones\")\n",
    "predecir_con_svm(\"Dolor en la cabeza y n√°useas\")\n",
    "predecir_con_svm(\"Vomito constante y fiebre alta\")\n",
    "predecir_con_svm(\"Necesito ayuda inmediata, no puedo respirar bien\")\n",
    "predecir_con_svm(\"Dolor abdominal severo y v√≥mitos persistentes\")\n",
    "predecir_con_svm(\"Fatiga extrema y mareos al levantarme\")\n",
    "predecir_con_svm(\"Siento un dolor agudo en el o√≠do y p√©rdida de audici√≥n\")\n",
    "predecir_con_svm(\"Tengo fiebre alta y dolor de garganta\")\n",
    "predecir_con_svm(\"Me duele mucho la espalda baja y no puedo moverme bien\")\n",
    "predecir_con_svm(\"Tengo una herida profunda en la mano que no deja de sangrar\")\n",
    "predecir_con_svm(\"Estoy teniendo dificultad para hablar y debilidad en un lado del cuerpo\")\n",
    "predecir_con_svm(\"Me salieron unas machas moradas en la piel y me siento muy cansado\")\n",
    "predecir_con_svm(\"Tengo llagas en la boca que me duelen mucho al comer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cb3feb",
   "metadata": {},
   "source": [
    "## Modelo Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6173aa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar embeddings pre-entrenados de FastText\n",
    "EMBEDDING_FILE = '../models/cc.es.300.vec'\n",
    "\n",
    "# Cargar el vocabulario de FastText en memoria (solo lo necesario)\n",
    "print(\"Cargando embeddings pre-entrenados...\")\n",
    "embeddings_index = {}\n",
    "with open(EMBEDDING_FILE, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.rstrip().rsplit(' ')\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(f'Se encontraron {len(embeddings_index)} vectores de palabras en FastText.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f87bb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# üöÄ ENTRENAMIENTO DEL MODELO DE DEEP LEARNING\n",
    "# ==============================================\n",
    "\n",
    "# --- 1. CONFIGURACI√ìN ---\n",
    "VOCAB_SIZE = 5000      # Vocabulario\n",
    "EMBEDDING_DIM = 300    # Dimensi√≥n FastText (¬°Debe ser 300!)\n",
    "MAX_LENGTH = 100       # Longitud de frase\n",
    "\n",
    "print(\"‚öôÔ∏è Configuraci√≥n cargada.\")\n",
    "\n",
    "# --- 2. PREPARACI√ìN DE EMBEDDINGS (MATRIZ DE PESOS) ---\n",
    "# Verificamos si ya tienes los embeddings cargados para no repetir el proceso pesado\n",
    "if 'embeddings_index' not in globals():\n",
    "    raise ValueError(\"‚ö†Ô∏è Por favor, carga el archivo .vec de FastText en la variable 'embeddings_index' antes de ejecutar este bloque.\")\n",
    "\n",
    "# Matriz de ceros inicial\n",
    "embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Tokenizer: Aprende el vocabulario de tus datos\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Rellenar matriz con FastText\n",
    "for word, i in word_index.items():\n",
    "    if i < VOCAB_SIZE:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            hits += 1\n",
    "        else:\n",
    "            misses += 1\n",
    "\n",
    "print(f\"‚úÖ Matriz de Embeddings lista. Hits: {hits} | Misses: {misses}\")\n",
    "\n",
    "# --- 3. PREPARACI√ìN DE DATOS (SECUENCIAS) ---\n",
    "train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "train_padded = pad_sequences(train_seq, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
    "test_padded = pad_sequences(test_seq, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "# Pesos para clases desbalanceadas (Crucial para que no ignore clases peque√±as)\n",
    "pesos = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "pesos_dict = dict(enumerate(pesos))\n",
    "print(\"‚öñÔ∏è Pesos de clase calculados.\")\n",
    "\n",
    "# --- 4. CONSTRUCCI√ìN DEL MODELO ---\n",
    "model = Sequential([\n",
    "    Input(shape=(MAX_LENGTH,)),\n",
    "    \n",
    "    # Capa de Embedding (Inicialmente CONGELADA)\n",
    "    Embedding(input_dim=VOCAB_SIZE, \n",
    "              output_dim=EMBEDDING_DIM, \n",
    "              weights=[embedding_matrix], \n",
    "              trainable=False,  # <--- FASE 1: NO TOCAR\n",
    "              name=\"embedding_layer\"),\n",
    "    \n",
    "    # Dropout espacial: apaga palabras enteras, no solo neuronas, fuerza a entender contexto\n",
    "    SpatialDropout1D(0.3),\n",
    "    \n",
    "    # LSTM Bidireccional potente\n",
    "    Bidirectional(LSTM(128, return_sequences=False)),\n",
    "    \n",
    "    # Clasificador\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(np.unique(y_train)), activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# --- 5. CALLBACKS INTELIGENTES ---\n",
    "# Detiene si no mejora en 5 √©pocas\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Reduce la velocidad de aprendizaje si se estanca (Ayuda a bajar el loss suavemente)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6, verbose=1)\n",
    "\n",
    "# ==========================================\n",
    "# üöÄ FASE 1: ENTRENAMIENTO GENERAL (CEREBRO)\n",
    "# ==========================================\n",
    "print(\"\\nüîµ FASE 1: Entrenando LSTM con Embeddings Congelados...\")\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history1 = model.fit(\n",
    "    train_padded, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(test_padded, y_test),\n",
    "    class_weight=pesos_dict,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# üöÄ FASE 2: FINE-TUNING (AJUSTE FINO)\n",
    "# ==========================================\n",
    "print(\"\\nüü¢ FASE 2: Descongelando Embeddings para Ajuste Fino (La magia)...\")\n",
    "\n",
    "# 1. Descongelamos la capa de Embedding\n",
    "model.get_layer(\"embedding_layer\").trainable = True\n",
    "\n",
    "# 2. Recompilamos con un Learning Rate MUY BAJO (1e-5)\n",
    "# Esto permite modificar los vectores de palabras suavemente sin romper lo aprendido\n",
    "optimizer_fine = Adam(learning_rate=1e-5)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer_fine, metrics=['accuracy'])\n",
    "\n",
    "# 3. Entrenamos de nuevo (Fine-Tuning)\n",
    "history2 = model.fit(\n",
    "    train_padded, y_train,\n",
    "    epochs=15,\n",
    "    batch_size=32,\n",
    "    validation_data=(test_padded, y_test),\n",
    "    class_weight=pesos_dict,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nüèÜ Entrenamiento Completado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9a5349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo\n",
    "model.save('../models/mi_red_neuronal_v5.h5')\n",
    "\n",
    "with open('../models/tokenizer_v5.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('../models/label_encoder_v5.pickle', 'wb') as handle:\n",
    "    pickle.dump(label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"‚úÖ Modelo de Red Neuronal entrenado y guardado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6d1743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico de Aprendizaje\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history1.history['accuracy'], label='Entrenamiento')\n",
    "plt.plot(history1.history['val_accuracy'], label='Validaci√≥n (Prueba)')\n",
    "plt.title('Precisi√≥n de la Red Neuronal durante el entrenamiento')\n",
    "plt.xlabel('√âpocas')\n",
    "plt.legend()\n",
    "\n",
    "# Comparaci√≥n Final\n",
    "loss, acc_dl = model.evaluate(test_padded, y_test, verbose=0)\n",
    "print(f\"\\nüèÜ RESUMEN FINAL:\")\n",
    "print(f\"Precisi√≥n Machine Learning (SVM): {acc_svm*100:.2f}%\")\n",
    "print(f\"Precisi√≥n Deep Learning (Red Neuronal): {acc_dl*100:.2f}%\")\n",
    "\n",
    "if acc_dl > acc_svm:\n",
    "    print(\"üöÄ ¬°La IA (Deep Learning) super√≥ al m√©todo cl√°sico!\")\n",
    "else:\n",
    "    print(\"üìä El m√©todo cl√°sico fue muy robusto, pero la IA tiene potencial de mejora con m√°s datos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d63332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç Ejecutando Aprendizaje No Supervisado (K-Means)...\")\n",
    "\n",
    "# Queremos agrupar en tantos grupos como especialidades creemos que hay (o un numero arbitrario ej: 5)\n",
    "num_clusters = 12\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)\n",
    "\n",
    "# Ver qu√© palabras definen a cada grupo\n",
    "print(\"\\nüß¨ PATRONES DESCUBIERTOS POR LA IA (Top palabras por grupo):\")\n",
    "order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = tfidf.get_feature_names_out()\n",
    "\n",
    "diccionario_clusters = {}\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    print(f\"\\nGrupo {i}: \", end='')\n",
    "    palabras_clave = [terms[ind] for ind in order_centroids[i, :8]] # Top 8 palabras\n",
    "    print(\", \".join(palabras_clave))\n",
    "    diccionario_clusters[i] = palabras_clave\n",
    "\n",
    "print(\"\\n‚úÖ Clustering completado. Estos grupos se formaron matem√°ticamente sin ayuda humana.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f10627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# üöë DEMO INTERACTIVA: TRIAJE 593\n",
    "# ==========================================\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"es_core_news_sm\")\n",
    "except:\n",
    "    import os\n",
    "    os.system(\"python -m spacy download es_core_news_sm\")\n",
    "    nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "def procesar_texto_para_demo(texto):\n",
    "    doc = nlp(texto)\n",
    "    tokens_limpios = []\n",
    "    for token in doc:\n",
    "        if not token.is_punct and not token.is_stop and token.is_alpha:\n",
    "            tokens_limpios.append(token.lemma_.lower())\n",
    "    return \" \".join(tokens_limpios)\n",
    "\n",
    "def predecir_urgencia(texto_usuario):\n",
    "    # 1. Limpieza\n",
    "    texto_limpio = procesar_texto_para_demo(texto_usuario)\n",
    "    if not texto_limpio: # Si el usuario pone solo simbolos o stopwords\n",
    "        print(\"‚ö†Ô∏è Por favor escribe una frase m√©dica v√°lida.\")\n",
    "        return\n",
    "    seq = tokenizer.texts_to_sequences([texto_limpio])\n",
    "    padded = pad_sequences(seq, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
    "    \n",
    "    # 2. Predicci√≥n con la Red Neuronal\n",
    "    prediccion = model.predict(padded, verbose=0)\n",
    "    \n",
    "    # 3. Decodificar el resultado\n",
    "    clase_predicha_index = np.argmax(prediccion)\n",
    "    probabilidad = np.max(prediccion)\n",
    "    etiqueta = label_encoder.inverse_transform([clase_predicha_index])[0]\n",
    "    \n",
    "    # 4. Resultado visual\n",
    "    print(f\"üë§ Usuario dice: '{texto_usuario}'\")\n",
    "    print(f\"üß† La IA entiende: '{texto_limpio}'\") # Para que veas como piensa la maquina\n",
    "    print(f\"üè• Especialidad: {etiqueta.upper()}\")\n",
    "    print(f\"üìä Confianza: {probabilidad*100:.2f}%\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# --- PRUEBA DE PROYECTO ---\n",
    "print(\"üöÄ Iniciando pruebas de Triaje Inteligente...\\n\")\n",
    "\n",
    "# Casos de prueba (Pru√©balos y luego cambia el texto por lo que quieras)\n",
    "predecir_urgencia(\"El paciente presenta dolor fuerte en el pecho y dificultad para respirar\")\n",
    "predecir_urgencia(\"Tengo una mancha roja en la piel que me pica mucho\")\n",
    "predecir_urgencia(\"Dolor intenso en el ojo derecho y visi√≥n borrosa\")\n",
    "predecir_urgencia(\"Fractura en la pierna tras ca√≠da\")\n",
    "predecir_urgencia(\"Ardor al orinar y dolor en los ri√±ones\")\n",
    "predecir_urgencia(\"Dolor en la cabeza y n√°useas\")\n",
    "predecir_urgencia(\"Vomito constante y fiebre alta\")\n",
    "predecir_urgencia(\"Necesito ayuda inmediata, no puedo respirar bien\")\n",
    "predecir_urgencia(\"Dolor abdominal severo y v√≥mitos persistentes\")\n",
    "predecir_urgencia(\"Fatiga extrema y mareos al levantarme\")\n",
    "predecir_urgencia(\"Siento un dolor agudo en el o√≠do y p√©rdida de audici√≥n\")\n",
    "predecir_urgencia(\"Tengo fiebre alta y dolor de garganta\")\n",
    "predecir_urgencia(\"Me duele mucho la espalda baja y no puedo moverme bien\")\n",
    "predecir_urgencia(\"Tengo una herida profunda en la mano que no deja de sangrar\")\n",
    "predecir_urgencia(\"Estoy teniendo dificultad para hablar y debilidad en un lado del cuerpo\")\n",
    "predecir_urgencia(\"Me salieron unas machas moradas en la piel y me siento muy cansado\")\n",
    "predecir_urgencia(\"Tengo llagas en la boca que me duelen mucho al comer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
